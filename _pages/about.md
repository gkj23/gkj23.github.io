---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


## ğŸ“ Academic Background

I am currently an undergraduate student in the **Department of Computer Science and Technology** at **Tsinghua University**, a member of the Class of 2023.

As of the end of my sophomore year, my academic standing is **GPA 3.90** (ranked **23/171** in the cohort). Notably, **all core Computer Science courses and fundamental Mathematics courses were completed with a 4.0**.

Prior to this, I completed my high school education in Jinan, Shandong Province, where I achieved a score of **704** on the National College Entrance Examination, ranking among the **Top 10** students in the province.

## ğŸ‘©â€ğŸ’» Research Experience

During my undergraduate studies, I have been actively involved in research internships under the guidance of **Prof. Song-Hai Zhang**, **Prof. Xiao-Lin Hu**, and **Prof. Hao Zhao**.

### Key Achievements
* **SRT Project (Prof. Zhang):** My individual work on the Student Research Training (SRT) project under Prof. Zhang received the **A+ grade (Highest)**, demonstrating exceptional research output.
* **Research Grant (Prof. Hu):** During my internship with Prof. Hu, I successfully initiated and secured a **20,000 RMB** grant through the competitive university-level "Xuetui Plan" (Student Research Promotion Program).



## ğŸ”¬ Research Interests

Broadly speaking, my research centers on the **perception, understanding, and generation of visual and auditory modalities**. My ultimate goal is to construct a **highly realistic and interactive audiovisual world**, serving as a foundation to achieve **Spatial Intelligence** capable of robust perception, understanding, and reasoning.

Specifically, I focus (or plan to focus) on the following areas:

### 1. 3D Vision
* **3D Representation Learning:** Amidst the current fragmented landscape of 3D representations (e.g., Voxels, NeRF, Gaussian Splatting), I aim to explore and define a **unified 3D representation paradigm**.
* **3D Scene Generation & Reconstruction:** Generating interactive and physically plausible 3D scenes.

### 2. Spatial Audio
*(For a comprehensive overview, refer to the survey: [ASAudio: A Survey of Advanced Spatial Audio Research](https://arxiv.org/abs/2508.10924))*

* **Acoustic Field Reconstruction & Generation:** Inspired by works such as [NeRAF](https://amandinebtto.github.io/NeRAF/) and [AV-DAR](https://humathe.github.io/avdar/), I am developing a **feedforward Audio-Visual Gaussian Splatting (AV-GS) framework**. This approach supports multiple sound sources and generalizes across scenes without requiring per-scene optimization. (**Ongoing**)
* **Unified Spatial Sound Generation:** Developing a unified framework capable of generating spatial audio from diverse inputs, including text, egocentric video, 360Â° video, and audio.
* **Spatial Sound Perception & Reasoning:** Investigating how **Multimodal LLMs (MLLMs)** perform reasoning using spatial sound, and how Embodied AI frameworks (e.g., **Vision-Language-Action (VLA)** models) utilize spatial audio for decision-making.

### 3. Multimodal Large Language Models (MLLM)
* **Robustness in Audiovisual Contexts:** Benchmarking and enhancing MLLM performance under challenging conditions, such as noisy environments, multi-speaker audio, or extremely low-quality visual inputs. (**Ongoing**)
* **Enhancing Spatial Intelligence:** Improving performance on downstream spatial tasks, including but not limited to:
    * **Vision-and-Language Navigation (VLN)**
    * **3D Object Detection & Grounding**
    * **Spatial Question Answering (Spatial QA)**
* **MLLM Paradigm Research:** Critically examining current multimodal alignment paradigms (e.g., designing specific discrete tokenizers or continuous encoders for each modality). I aim to investigate whether this is the path to true multimodal intelligence or merely an expedient, short-sighted solution for simplicity.


## ğŸ“š Publications / Works

* **[è®ºæ–‡æ ‡é¢˜ 1]** (Authors: [Your Name], Prof. Zhang, et al.). *[Conference/Journal Name], Year.* [Optional Link]
* **[è®ºæ–‡æ ‡é¢˜ 2]** (Authors: Prof. Hu, [Your Name], et al.). *[Conference/Journal Name], Year.* [Optional Link]
* **[è®ºæ–‡æ ‡é¢˜ 3]** (Authors: [Your Name], Prof. Zhao, et al.). *[Conference/Journal Name], Year.* [Optional Link]
* **[é¡¹ç›®/é¢„å°æœ¬]** [Project Name/Preprint Title]. [Link to GitHub/arXiv]


## ğŸ† Awards

* **2024-2025 Academic Year:** Awarded the **"KuanDe" Comprehensive Excellence Scholarship** (å®½å¾·ç»¼åˆä¼˜ç§€å¥–å­¦é‡‘).
* **2023-2024 Academic Year:** Awarded the **"Tsinghua Friend-Huawei" Comprehensive Excellence Scholarship** (æ¸…åä¹‹å‹-åä¸ºç»¼åˆä¼˜ç§€å¥–å­¦é‡‘).

